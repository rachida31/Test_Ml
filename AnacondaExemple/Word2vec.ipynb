{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6647179 ,  1.0910058 , -0.72085845, -0.6931582 , -0.3491546 ,\n",
       "       -0.9255777 ,  0.78966486,  1.5558457 ,  0.8096707 ,  0.04013576,\n",
       "       -1.8671646 ,  0.49984232, -0.18524824, -0.552432  , -1.127025  ,\n",
       "       -1.6343294 ,  0.40954483,  1.4451025 ,  0.49586126,  1.8007085 ,\n",
       "       -1.4436576 , -0.32717168,  1.0135076 ,  1.6971691 ,  0.05813472,\n",
       "       -2.4995332 , -0.13361377,  1.5594677 ,  0.4157923 ,  1.1484382 ,\n",
       "        1.1631846 , -0.34370553,  0.06018662, -0.47846168, -1.2699313 ,\n",
       "       -1.2447286 , -0.109083  , -0.4326124 , -1.3921127 ,  1.4142797 ,\n",
       "       -1.0087551 ,  3.0353742 , -0.21573026, -0.34378222, -1.3377184 ,\n",
       "        2.5178502 , -1.6089766 , -1.4561623 , -2.07325   ,  1.0594691 ,\n",
       "       -0.65816844,  2.9645102 ,  0.96333194, -0.8749611 , -0.3860393 ,\n",
       "       -0.45364666,  1.869631  ,  0.9347763 , -2.6552455 ,  0.5043463 ,\n",
       "        0.55622864,  0.5570379 ,  0.24029694,  0.0859979 ,  3.195965  ,\n",
       "       -1.366473  , -1.1995682 , -1.0624795 ,  0.4680774 ,  0.13958055,\n",
       "       -0.24590924,  0.02285096,  0.88795686, -0.5465915 ,  0.28785843,\n",
       "       -0.34708533,  0.73459363,  0.82184243,  1.5857103 , -0.16343248,\n",
       "        0.97075355, -1.0208664 , -0.01641171, -2.3055012 ,  0.516725  ,\n",
       "        0.07193814,  2.1027453 , -0.6891128 ,  1.0066174 , -1.8251215 ,\n",
       "       -0.35296378, -0.21367723, -0.3785083 ,  0.40374696, -0.24635379,\n",
       "       -0.8991349 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "#charger le modèle français simple.\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "# traiter une phrase en utilisant le modèle\n",
    "doc = nlp ( \"Ceci est un texte que je traite avec Spacy\" )\n",
    "# Récupère le vecteur 'texte':\n",
    "doc [ 4 ] .vector\n",
    "# Obtenez le vecteur moyen pour la phrase entière (utile pour la classification des phrases, etc.)\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les vecteurs sont accessibles directement à l'aide de l'attribut .vector de chaque token a traité (mot). Le vecteur moyen pour la phrase entière est également calculé simplement à l'aide de .vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0265143 ,  2.7239542 , -5.0048556 ,  0.7257427 , -4.5300817 ,\n",
       "       -0.25007123,  2.345086  ,  0.18997467,  0.5005402 , -0.37956768,\n",
       "       -0.2795325 ,  4.0491633 ,  2.047511  ,  0.676478  ,  3.0325863 ,\n",
       "       -1.577316  ,  5.7206454 ,  0.9426545 ,  0.14595929,  3.3483772 ,\n",
       "       -2.1170335 , -1.231694  , -5.3810635 , -1.3933394 , -4.056142  ,\n",
       "        0.21993887,  0.6674843 ,  2.2604933 , -0.4150899 ,  4.502517  ,\n",
       "       -2.1294646 ,  5.4568644 , -2.1734705 ,  4.801753  , -3.9682686 ,\n",
       "       -4.855811  , -0.08344412, -4.283447  , -4.328655  , -0.5942766 ,\n",
       "       -1.9755992 ,  4.418608  , -1.6546574 , -0.44446576, -3.772001  ,\n",
       "        2.2524805 , -0.65054476,  2.2739244 , -5.039021  ,  3.9841528 ,\n",
       "       -0.6333385 ,  2.2404227 , -1.9977565 ,  2.8205366 , -2.4850612 ,\n",
       "       -0.64855987,  2.7708547 ,  2.462861  , -4.6444483 ,  1.2306913 ,\n",
       "        3.5711174 ,  0.5962813 , -0.00998145,  1.8171425 ,  5.6852083 ,\n",
       "        0.9902173 ,  5.1536727 , -5.011366  ,  1.0806334 ,  0.31897518,\n",
       "       -2.4779701 , -1.6915054 ,  6.107071  , -1.0884566 ,  1.6426264 ,\n",
       "        1.8664346 , -6.65347   , -1.4681721 ,  3.7333732 , -2.4548979 ,\n",
       "        0.5022913 , -0.28253496, -0.857419  , -6.407176  , -0.87019646,\n",
       "        0.09264451,  5.711297  ,  1.0158805 ,  1.8130622 , -2.603583  ,\n",
       "        5.3443    , -0.5471986 , -3.8724942 ,  1.6283977 , -2.679077  ,\n",
       "       -2.851722  ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc [ 4 ] .vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gensim  n'est pas livré avec les mêmes modèles intégrés que Spacy, donc pour charger un modèle pré-entraîné dans Gensim, on doit d'abord en trouver et en télécharger modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "TEXT_DATA_DIR = 'C:/Users/lenovo/Downloads/20news/20_newsgroups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 texts.\n"
     ]
    }
   ],
   "source": [
    "# Newsgroups data is split between many files and folders.\n",
    "# Directory stucture 20_newsgroup/<newsgroup label>/<post ID>\n",
    "\n",
    "texts = []         # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []        # list of label ids\n",
    "label_text = []    # list of label texts\n",
    "\n",
    "# Go through each directory\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            # News groups posts are named as numbers, with no extensions.\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                f = open(fpath, encoding='latin-1')\n",
    "                t = f.read()\n",
    "                i = t.find('\\n\\n')  # skip header in file (starts with two newlines.)\n",
    "                if 0 < i:\n",
    "                    t = t[i:]\n",
    "                texts.append(t)\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "                label_text.append(name)\n",
    "\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data - remove punctuation from every newsgroup text\n",
    "sentences = []\n",
    "# Go through each text in turn\n",
    "for ii in range(len(texts)):\n",
    "    sentences = [re.sub(pattern=r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', \n",
    "                        repl='', \n",
    "                        string=x\n",
    "                       ).strip().split(' ') for x in texts[ii].split('\\n') \n",
    "                      if not x.endswith('writes:')]\n",
    "    sentences = [x for x in sentences if x != ['']]\n",
    "    texts[ii] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'motto', 'originated', 'in', 'the', 'StarSpangled', 'Banner', '', 'Tell', 'me', 'that', 'this', 'has'], ['something', 'to', 'do', 'with', 'atheists'], ['The', 'motto', 'oncoins', 'originated', 'as', 'a', 'McCarthyite', 'smear', 'which', 'equated', 'atheism'], ['with', 'Communism', 'and', 'called', 'both', 'unamerican'], ['No', 'it', \"didn't\", '', 'The', 'motto', 'has', 'been', 'on', 'various', 'coins', 'since', 'the', 'Civil', 'War'], ['It', 'was', 'just', 'required', 'to', 'be', 'on', 'all', 'currency', 'in', 'the', \"50's\"], ['keith']]\n"
     ]
    }
   ],
   "source": [
    "print(texts[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all sentences from all texts into a single list of sentences\n",
    "all_sentences = []\n",
    "for text in texts:\n",
    "    all_sentences += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all sentences from all texts into a single list of sentences\n",
    "all_sentences = []\n",
    "for text in texts:\n",
    "    all_sentences += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase Detection\n",
    "# Give some common terms that can be ignored in phrase detection\n",
    "# For example, 'state_of_affairs' will be detected because 'of' is provided here: \n",
    "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "# Create the relevant phrases from the list of sentences:\n",
    "phrases = Phrases(all_sentences, common_terms=common_terms)\n",
    "# The Phraser object is used from now on to transform sentences\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "# Applying the Phraser to transform our sentences is simply\n",
    "all_sentences = list(bigram[all_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_sentences, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=200,      # Dimensionality of word embeddings\n",
    "                 workers=2,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)       # Number of epochs training over corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-c854c427bf40>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model.most_similar(\"machine\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('modem', 0.5224773287773132),\n",
       " ('system', 0.48703402280807495),\n",
       " ('hard_disk', 0.4633997678756714),\n",
       " ('mouse', 0.4599805474281311),\n",
       " ('computer', 0.4442451000213623),\n",
       " ('controller', 0.4432569742202759),\n",
       " ('client', 0.4394943118095398),\n",
       " ('mac', 0.43801236152648926),\n",
       " ('drive', 0.43596261739730835),\n",
       " ('workstation', 0.4348524212837219)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
